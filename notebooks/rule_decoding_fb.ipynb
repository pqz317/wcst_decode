{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask if rule can be decoded during fb period if we only look at correct last 8 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "import utils.io_utils as io_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from trial_splitters.kfold_splitter import KFoldSplitter\n",
    "from trial_splitters.feature_block_splitter import FeatureBlockSplitter\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from models.value_models import ValueNormedModel, ValueNormedDropoutModel\n",
    "import pickle\n",
    "\n",
    "from models.multinomial_logistic_regressor import NormedDropoutMultinomialLogisticRegressor\n",
    "from models.model_wrapper import ModelWrapper, ModelWrapperLinearRegression\n",
    "\n",
    "from models.trainer import Trainer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import scipy.stats as sci_stats\n",
    "import scipy\n",
    "\n",
    "from itertools import accumulate\n",
    "\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 300\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "\n",
    "\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. \n",
    "\n",
    "feature_dims = [\"Color\", \"Shape\", \"Pattern\"]\n",
    "\n",
    "pre_interval = 1300\n",
    "post_interval = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "fs = s3fs.S3FileSystem()\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "# only look at corrects for this one\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\"])]   \n",
    "shuffled_card_idxs = behavioral_utils.get_shuffled_card_idxs(valid_beh)\n",
    "valid_beh = valid_beh[valid_beh.TrialNumber >= 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rules with more than 5 blocks associated with them\n",
    "num_rules = valid_beh.groupby([\"CurrentRule\"]).apply(lambda x: len(x.BlockNumber.unique()))\n",
    "rules_more_than_five = num_rules[num_rules > 5].index.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "last_n = 8\n",
    "\n",
    "def label_trials(block_group, last_n):\n",
    "    block_len = len(block_group)\n",
    "    block_group[\"TrialUntilRuleChange\"] = block_len - block_group[\"TrialAfterRuleChange\"]\n",
    "    last_eight = block_group[block_group[\"TrialUntilRuleChange\"] <= last_n]\n",
    "    return last_eight\n",
    "block_groups = valid_beh.groupby([\"BlockNumber\"], as_index=False)\n",
    "only_last_n = block_groups.apply(label_trials, last_n).reset_index()\n",
    "\n",
    "valid_beh = valid_beh[\n",
    "    (valid_beh.TrialNumber.isin(only_last_n.TrialNumber)) & \n",
    "    (valid_beh.CurrentRule.isin(rules_more_than_five)) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frs = pd.read_pickle(fs.open(\"l2l.pqz317.scratch/firing_rates_1300_fb_1500_100_bins.pickle\"))\n",
    "feature_selections = pd.read_pickle(fs.open(\"l2l.pqz317.scratch/feature_selections.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at trial numbers of last eights\n",
    "frs = frs[frs.TrialNumber.isin(valid_beh.TrialNumber)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = len(frs.UnitID.unique())\n",
    "classes = valid_beh[\"CurrentRule\"].unique()\n",
    "init_params = {\"n_inputs\": num_neurons, \"p_dropout\": 0.5, \"n_classes\": len(classes)}\n",
    "trainer = Trainer(learning_rate=0.01)\n",
    "wrapped = ModelWrapper(NormedDropoutMultinomialLogisticRegressor, init_params, trainer, classes)\n",
    "\n",
    "mode = \"SpikeCounts\"\n",
    "\n",
    "# prep data for classification\n",
    "inputs = frs.rename(columns={mode: \"Value\"})\n",
    "labels = valid_beh.rename(columns={\"CurrentRule\": \"Feature\"})\n",
    "\n",
    "splitter = RandomSplitter(valid_beh.TrialNumber.unique(), 20, 0.2)\n",
    "\n",
    "outputs = classifier_utils.evaluate_classifiers_by_time_bins(\n",
    "    wrapped, inputs, labels, np.arange(0, 2.8, 0.1), splitter\n",
    ")\n",
    "io_utils.save_model_outputs(\n",
    "    fs, \n",
    "    f\"fb_rule_last_eights_normed_dropout\", \n",
    "    f\"{pre_interval}_fb_{post_interval}\",\n",
    "    \"random_split\",\n",
    "    outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
