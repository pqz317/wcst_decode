{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to decode which feature was selected per-trial based on firing rates of neurons\n",
    "# experiment with ranges of firing rates around fixation (selection) time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "import utils.io_utils as io_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from models.model_wrapper import ModelWrapper\n",
    "from models.multinomial_logistic_regressor import (\n",
    "    MultinomialLogisticRegressor, \n",
    "    NormedMultinomialLogisticRegressor,\n",
    "    NormedDropoutMultinomialLogisticRegressor,\n",
    ")\n",
    "from models.multi_layer import MultiLayer\n",
    "\n",
    "from models.trainer import Trainer\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "from itertools import accumulate\n",
    "\n",
    "import torch\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. \n",
    "pre_interval = 1300\n",
    "post_interval = 2000\n",
    "\n",
    "feature_dims = [\"Color\", \"Shape\", \"Pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "fs = s3fs.S3FileSystem()\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]   \n",
    "valid_beh = valid_beh[valid_beh.TrialNumber >= 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rates_50 = pd.read_pickle(fs.open(f\"l2l.pqz317.scratch/firing_rates_{pre_interval}_fb_{post_interval}_50_bins.pickle\"))\n",
    "firing_rates_50 = firing_rates_50[firing_rates_50.TrialNumber >= 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_codes = [200 if res == \"Correct\" else 206 for res in valid_beh.Response.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_exploit = lfp_development.get_exploration(np.array(response_codes), 1)\n",
    "valid_beh[\"explore\"] = explore_exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_trials = valid_beh[valid_beh.explore == 1]\n",
    "exploit_trials = valid_beh[valid_beh.explore == 0]\n",
    "\n",
    "print(f\"Number of correct trials in explore state: {len(explore_trials[explore_trials.Response == 'Correct'])}\")\n",
    "print(f\"Number of incorrect trials in explore state: {len(explore_trials[explore_trials.Response == 'Incorrect'])}\")\n",
    "print(f\"Number of correct trials in exploit state: {len(exploit_trials[exploit_trials.Response == 'Correct'])}\")\n",
    "print(f\"Number of incorrect trials in exploit state: {len(exploit_trials[exploit_trials.Response == 'Incorrect'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "num_samples = 285 # smallest common number\n",
    "explore_cor_sampled = explore_trials[explore_trials.Response == 'Correct'].sample(num_samples, random_state=rng)\n",
    "explore_inc_sampled = explore_trials[explore_trials.Response == 'Incorrect'].sample(num_samples, random_state=rng)\n",
    "exploit_cor_sampled = exploit_trials[exploit_trials.Response == 'Correct'].sample(num_samples, random_state=rng)\n",
    "exploit_inc_sampled = exploit_trials[exploit_trials.Response == 'Incorrect'].sample(num_samples, random_state=rng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at specific neuron firing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_id = 52\n",
    "\n",
    "unit_fr = firing_rates_50[firing_rates_50.UnitID == neuron_id]\n",
    "\n",
    "explore_cor_fr = unit_fr[unit_fr.TrialNumber.isin(explore_cor_sampled.TrialNumber)]\n",
    "explore_inc_fr = unit_fr[unit_fr.TrialNumber.isin(explore_inc_sampled.TrialNumber)]\n",
    "exploit_cor_fr = unit_fr[unit_fr.TrialNumber.isin(exploit_cor_sampled.TrialNumber)]\n",
    "exploit_inc_fr = unit_fr[unit_fr.TrialNumber.isin(exploit_inc_sampled.TrialNumber)]\n",
    "\n",
    "trans_explore_cor = np.stack(explore_cor_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "trans_explore_inc = np.stack(explore_inc_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "trans_exploit_cor = np.stack(exploit_cor_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "trans_exploit_inc = np.stack(exploit_inc_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    trans_explore_cor,\n",
    "    1.3, 2, .05,\n",
    "    axs[0],\n",
    "    label=\"Explore Correct\",\n",
    "    right_align=True\n",
    ")\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    trans_explore_inc,\n",
    "    1.3, 2, .05,\n",
    "    axs[0],\n",
    "    label=\"Explore Incorrect\",\n",
    "    right_align=True\n",
    ")\n",
    "axs[0].axvspan(-0.8, 0, alpha=0.3, color='gray')\n",
    "axs[0].axvline(0.098, alpha=0.3, color='gray', linestyle='dashed')\n",
    "axs[0].set_xlabel(\"Time Relative to Feedback (s)\")\n",
    "axs[0].set_ylabel(\"Unit 52 Spike Counts\")\n",
    "axs[0].legend()\n",
    "\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    trans_exploit_cor,\n",
    "    1.3, 2, .05,\n",
    "    axs[1],\n",
    "    label=\"Exploit Correct\",\n",
    "    right_align=True\n",
    ")\n",
    "visualization_utils.visualize_accuracy_across_time_bins(\n",
    "    trans_exploit_inc,\n",
    "    1.3, 2, .05,\n",
    "    axs[1],\n",
    "    label=\"Exploit Incorrect\",\n",
    "    right_align=True\n",
    ")\n",
    "axs[1].axvspan(-0.8, 0, alpha=0.3, color='gray')\n",
    "axs[1].axvline(0.098, alpha=0.3, color='gray', linestyle='dashed')\n",
    "axs[1].set_xlabel(\"Time Relative to Feedback (s)\")\n",
    "axs[1].set_ylabel(\"Unit 52 Spike Counts\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One big for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron_id in range(59):\n",
    "    unit_fr = firing_rates_50[firing_rates_50.UnitID == neuron_id]\n",
    "\n",
    "    explore_cor_fr = unit_fr[unit_fr.TrialNumber.isin(explore_cor_sampled.TrialNumber)]\n",
    "    explore_inc_fr = unit_fr[unit_fr.TrialNumber.isin(explore_inc_sampled.TrialNumber)]\n",
    "    exploit_cor_fr = unit_fr[unit_fr.TrialNumber.isin(exploit_cor_sampled.TrialNumber)]\n",
    "    exploit_inc_fr = unit_fr[unit_fr.TrialNumber.isin(exploit_inc_sampled.TrialNumber)]\n",
    "\n",
    "    trans_explore_cor = np.stack(explore_cor_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "    trans_explore_inc = np.stack(explore_inc_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "    trans_exploit_cor = np.stack(exploit_cor_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "    trans_exploit_inc = np.stack(exploit_inc_fr.groupby([\"TimeBins\"], as_index=False).apply(lambda x: x[\"SpikeCounts\"].to_numpy()).to_numpy())\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    visualization_utils.visualize_accuracy_across_time_bins(\n",
    "        trans_explore_cor,\n",
    "        1.3, 2, .05,\n",
    "        axs[0],\n",
    "        label=\"Explore Correct\",\n",
    "        right_align=True\n",
    "    )\n",
    "    visualization_utils.visualize_accuracy_across_time_bins(\n",
    "        trans_explore_inc,\n",
    "        1.3, 2, .05,\n",
    "        axs[0],\n",
    "        label=\"Explore Incorrect\",\n",
    "        right_align=True\n",
    "    )\n",
    "    axs[0].axvspan(-0.8, 0, alpha=0.3, color='gray')\n",
    "    axs[0].axvline(0.098, alpha=0.3, color='gray', linestyle='dashed')\n",
    "    axs[0].set_xlabel(\"Time Relative to Feedback (s)\")\n",
    "    axs[0].set_ylabel(f\"Unit {neuron_id} Spike Counts\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    visualization_utils.visualize_accuracy_across_time_bins(\n",
    "        trans_exploit_cor,\n",
    "        1.3, 2, .05,\n",
    "        axs[1],\n",
    "        label=\"Exploit Correct\",\n",
    "        right_align=True\n",
    "    )\n",
    "    visualization_utils.visualize_accuracy_across_time_bins(\n",
    "        trans_exploit_inc,\n",
    "        1.3, 2, .05,\n",
    "        axs[1],\n",
    "        label=\"Exploit Incorrect\",\n",
    "        right_align=True\n",
    "    )\n",
    "    axs[1].axvspan(-0.8, 0, alpha=0.3, color='gray')\n",
    "    axs[1].axvline(0.098, alpha=0.3, color='gray', linestyle='dashed')\n",
    "    axs[1].set_xlabel(\"Time Relative to Feedback (s)\")\n",
    "    axs[1].set_ylabel(f\"Unit {neuron_id} Spike Counts\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.savefig(f\"../data/responses/{neuron_id}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
