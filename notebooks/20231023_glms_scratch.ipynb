{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a stab at implementing GLMs \n",
    "With params: \n",
    "- RPE\n",
    "- Features\n",
    "- RPE and Features interaction terms\n",
    "\n",
    "Find units that significantly improve with the inclusion variance explained with interaction terms, either:\n",
    "- Before or during selection\n",
    "- during feedback\n",
    "\n",
    "Results are: \n",
    "- Per unit per time, Fraction of deviance explained. \n",
    "- For each model, per unit per time, weights\n",
    "- corresponding shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "from models.trainer import Trainer\n",
    "from models.model_wrapper import ModelWrapperRegression\n",
    "from models.multinomial_logistic_regressor import MultinomialLogisticRegressor\n",
    "from torch.nn import PoissonNLLLoss\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_name = 20180802\n",
    "\n",
    "FEATURE_DIMS = [\"Color\", \"Shape\", \"Pattern\"]\n",
    "OUTPUT_DIR = \"/data/patrick_res/information\"\n",
    "\n",
    "SESSIONS_PATH = \"/data/patrick_res/multi_sess/valid_sessions_rpe.pickle\"\n",
    "SESS_BEHAVIOR_PATH = \"/data/rawdata/sub-SA/sess-{sess_name}/behavior/sub-SA_sess-{sess_name}_object_features.csv\"\n",
    "\n",
    "PRE_INTERVAL = 1300\n",
    "POST_INTERVAL = 1500\n",
    "INTERVAL_SIZE = 100\n",
    "SMOOTH = 1\n",
    "EVENT = \"FeedbackOnset\"\n",
    "fr_path = f\"/data/patrick_res/multi_sess/{sess_name}/{sess_name}_firing_rates_{PRE_INTERVAL}_{EVENT}_{POST_INTERVAL}_{INTERVAL_SIZE}_bins_{SMOOTH}_smooth.pickle\"\n",
    "\n",
    "POSSIBLE_RPE_GROUPS = [\"more_neg\", \"less_neg\", \"less_pos\", \"more_pos\"]\n",
    "POSSIBLE_FEATURES = [\n",
    "    'CIRCLE', 'SQUARE', 'STAR', 'TRIANGLE', \n",
    "    'CYAN', 'GREEN', 'MAGENTA', 'YELLOW', \n",
    "    'ESCHER', 'POLKADOT', 'RIPPLE', 'SWIRL'\n",
    "]\n",
    "POSSIBLE_INTERACTIONS = [f\"{feat}_{rpe}\" for feat, rpe in itertools.product(POSSIBLE_FEATURES, POSSIBLE_RPE_GROUPS)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_path = SESS_BEHAVIOR_PATH.format(sess_name=sess_name)\n",
    "beh = pd.read_csv(behavior_path)\n",
    "frs = pd.read_pickle(fr_path)\n",
    "\n",
    "# filter trials \n",
    "valid_beh = behavioral_utils.get_valid_trials(beh)\n",
    "feature_selections = behavioral_utils.get_selection_features(valid_beh)\n",
    "valid_beh = pd.merge(valid_beh, feature_selections, on=\"TrialNumber\")\n",
    "valid_beh_rpes = behavioral_utils.get_rpes_per_session(sess_name, valid_beh)\n",
    "\n",
    "neg_med = valid_beh_rpes[valid_beh_rpes.RPE_FE < 0].RPE_FE.median()\n",
    "pos_med = valid_beh_rpes[valid_beh_rpes.RPE_FE > 0].RPE_FE.median()\n",
    "\n",
    "# add median labels to \n",
    "def add_group(row):\n",
    "    rpe = row.RPE_FE\n",
    "    group = None\n",
    "    if rpe < neg_med:\n",
    "        group = \"more_neg\"\n",
    "    elif rpe >= neg_med and rpe < 0:\n",
    "        group = \"less_neg\"\n",
    "    elif rpe >= 0 and rpe < pos_med:\n",
    "        group = \"less_pos\"\n",
    "    elif rpe > pos_med:\n",
    "        group = \"more_pos\"\n",
    "    row[\"RPEGroup\"] = group\n",
    "    return row\n",
    "valid_beh = valid_beh_rpes.apply(add_group, axis=1)\n",
    "for feature_dim in FEATURE_DIMS:\n",
    "    valid_beh[f\"{feature_dim}RPE\"] = valid_beh[feature_dim] + \"_\" + valid_beh[\"RPEGroup\"]\n",
    "\n",
    "valid_beh = valid_beh.set_index(\"TrialNumber\")\n",
    "frs = frs.set_index(\"TrialNumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 9\n",
    "unit_frs = frs[frs.UnitID == unit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_columns(beh, columns):\n",
    "    flattened_columns = []\n",
    "    for column in columns:\n",
    "        values = beh[column].unique()\n",
    "        for value in values:\n",
    "            beh[value] = (beh[column] == value).astype(int)\n",
    "        flattened_columns.extend(values)\n",
    "    return beh, flattened_columns\n",
    "\n",
    "def fit_glm(df, x_cols, y_col):\n",
    "    ys = df[y_col].values\n",
    "    xs = df[x_cols].values\n",
    "    model = PoissonRegressor(alpha=1)\n",
    "    model = model.fit(xs, ys)\n",
    "    return pd.Series({\"score\": model.score(xs, ys)})\n",
    "\n",
    "def fit_glm_torch(df, x_cols, y_col):\n",
    "    ys = df[y_col].values\n",
    "    xs = df[x_cols].values\n",
    "    init_params = {\"n_inputs\": xs.shape[1], \"n_classes\": 1}\n",
    "    # create a trainer object\n",
    "    trainer = Trainer(\n",
    "        learning_rate=0.05, \n",
    "        max_iter=500, \n",
    "        loss_fn=PoissonNLLLoss(log_input=True),\n",
    "        weight_decay=1\n",
    "    )\n",
    "    # create a wrapper for the decoder\n",
    "    model = ModelWrapperRegression(MultinomialLogisticRegressor, init_params, trainer)\n",
    "    model = model.fit(xs, ys)\n",
    "    return pd.Series({\"score\": model.score(xs, ys)})\n",
    "\n",
    "\n",
    "def fit_glms_by_time(data, x_inputs):\n",
    "    data, flattened_columns = flatten_columns(data, x_inputs)\n",
    "    res = data.groupby(\"TimeBins\").apply(lambda x: fit_glm(x, flattened_columns, \"SpikeCounts\")).reset_index()\n",
    "    # res = data.groupby(\"TimeBins\").apply(lambda x: fit_glm_torch(x, flattened_columns, \"SpikeCounts\")).reset_index()\n",
    "    return res.fillna(0)\n",
    "\n",
    "def create_shuffles(data, columns, rng):\n",
    "    for column in columns:\n",
    "        vals = data[column].values\n",
    "        rng.shuffle(vals)\n",
    "        data[column] = vals\n",
    "    return data\n",
    "\n",
    "def fit_n_shuffles(beh, frs, input_columns, shuffle_columns, num_shuffles):\n",
    "    rng = np.random.default_rng()\n",
    "    shuffled_reses = []\n",
    "    shuffle_beh = beh.copy()\n",
    "    beh_inputs_to_shuffle = shuffle_beh[input_columns]\n",
    "    for i in range(num_shuffles):\n",
    "        shuffled_inputs = create_shuffles(beh_inputs_to_shuffle, shuffle_columns, rng)\n",
    "        shuffled_data = pd.merge(shuffled_inputs, frs, on=\"TrialNumber\")\n",
    "        shuffled_res = fit_glms_by_time(shuffled_data, input_columns)\n",
    "        shuffled_res[\"ShuffledIdx\"] = i\n",
    "        shuffled_reses.append(shuffled_res)\n",
    "    shuffled = pd.concat(shuffled_reses)\n",
    "    return shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"RPEGroup\"]\n",
    "beh_inputs = valid_beh[input_columns]\n",
    "data = pd.merge(beh_inputs, unit_frs, on=\"TrialNumber\")\n",
    "rpe_res = fit_glms_by_time(data, input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = fit_n_shuffles(\n",
    "    valid_beh, \n",
    "    unit_frs, \n",
    "    input_columns=input_columns, \n",
    "    shuffle_columns=input_columns,\n",
    "    num_shuffles=5\n",
    ")\n",
    "shuffled_max = shuffled.groupby(\"TimeBins\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "time_bins = rpe_res.TimeBins - 1.3\n",
    "ax.plot(time_bins, rpe_res.score, label=\"RPE\")\n",
    "ax.plot(time_bins, shuffled_max.score, label=\"Shuffled Max\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Fraction of Deviance explained\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPE + Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"RPEGroup\"] + FEATURE_DIMS\n",
    "beh_inputs = valid_beh[input_columns]\n",
    "data = pd.merge(beh_inputs, unit_frs, on=\"TrialNumber\")\n",
    "rpe_features_res = fit_glms_by_time(data, input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpe_features_shuffled = fit_n_shuffles(\n",
    "    valid_beh, \n",
    "    unit_frs, \n",
    "    input_columns=input_columns, \n",
    "    shuffle_columns=FEATURE_DIMS,\n",
    "    num_shuffles=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpe_features_shuffled_max = rpe_features_shuffled.groupby(\"TimeBins\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "time_bins = rpe_res.TimeBins - 1.3\n",
    "ax.plot(time_bins, rpe_res.score, label=\"RPE\")\n",
    "ax.plot(time_bins, rpe_features_shuffled_max.score, label=\"RPE + Shuffled Features Max\")\n",
    "ax.plot(time_bins, rpe_features_res.score, label=\"RPE + Features\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Fraction of Deviance explained\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPE + Features + Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIONS = [f\"{dim}RPE\" for dim in FEATURE_DIMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"RPEGroup\"] + FEATURE_DIMS + INTERACTIONS\n",
    "beh_inputs = valid_beh[input_columns]\n",
    "data = pd.merge(beh_inputs, unit_frs, on=\"TrialNumber\")\n",
    "interactions_res = fit_glms_by_time(data, input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_shuffled = fit_n_shuffles(\n",
    "    valid_beh, \n",
    "    unit_frs, \n",
    "    input_columns=input_columns, \n",
    "    shuffle_columns=INTERACTIONS,\n",
    "    num_shuffles=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_shuffled_max = interactions_shuffled.groupby(\"TimeBins\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "time_bins = rpe_res.TimeBins - 1.3\n",
    "ax.plot(time_bins, rpe_res.score, label=\"RPE Only\")\n",
    "ax.plot(time_bins, rpe_features_res.score, label=\"RPE + Features\")\n",
    "ax.plot(time_bins, interactions_shuffled_max.score, label=\"RPE + Features + Shuffled Interactions Max\")\n",
    "ax.plot(time_bins, interactions_res.score, label=\"RPE + Features + Interactions\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Fraction of Deviance explained\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
