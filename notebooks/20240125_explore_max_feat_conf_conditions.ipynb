{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another shot at dimensionality reduction techniques\n",
    "Want to try PCA again with the following features: \n",
    "- Try on either HC or OFC only cells, small number (19 in HC, 18 in OFC)\n",
    "- Condition on one selected feature at a time\n",
    "- Group trials into 3 groups: \n",
    "  - A: high feature val, high confidence\n",
    "  - B: low feature val, high confidence\n",
    "  - C: low feature val, low confidence\n",
    "Also, will want to try: \n",
    "- 50ms time bins, smoothed with 50ms std Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data, Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils.pseudo_utils as pseudo_utils\n",
    "import utils.pseudo_classifier_utils as pseudo_classifier_utils\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "from utils.session_data import SessionData\n",
    "import utils.io_utils as io_utils\n",
    "from utils.constants import *\n",
    "import json\n",
    "\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output directory to store the data\n",
    "OUTPUT_DIR = \"/data/patrick_res/pseudo\"\n",
    "# path to a dataframe of sessions to analyze\n",
    "# SESSIONS_PATH = \"/data/patrick_scratch/multi_sess/valid_sessions.pickle\"\n",
    "SESSIONS_PATH = \"/data/patrick_res/sessions/valid_sessions_rpe.pickle\"\n",
    "# path for each session, specifying behavior\n",
    "SESS_BEHAVIOR_PATH = \"/data/rawdata/sub-SA/sess-{sess_name}/behavior/sub-SA_sess-{sess_name}_object_features.csv\"\n",
    "# path for each session, for spikes that have been pre-aligned to event time and binned. \n",
    "SESS_SPIKES_PATH = \"/data/patrick_res/firing_rates/{sess_name}_firing_rates_{pre_interval}_{event}_{post_interval}_{interval_size}_bins_1_smooth.pickle\"\n",
    "\n",
    "FEATURE_DIMS = [\"Color\", \"Shape\", \"Pattern\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per session, label trials\n",
    "Need confidence values, as well as feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_for_session(session, feat):\n",
    "    behavior_path = SESS_BEHAVIOR_PATH.format(sess_name=session)\n",
    "\n",
    "    beh = pd.read_csv(behavior_path)\n",
    "    valid_beh = behavioral_utils.get_valid_trials(beh)\n",
    "    feature_selections = behavioral_utils.get_selection_features(valid_beh)\n",
    "    valid_beh_merged = pd.merge(valid_beh, feature_selections, on=\"TrialNumber\", how=\"inner\")\n",
    "    feat_dim = FEATURE_TO_DIM[feat]\n",
    "    valid_beh_merged = valid_beh_merged[valid_beh_merged[feat_dim] == feat]\n",
    "    valid_beh_vals = behavioral_utils.get_feature_values_per_session(session, valid_beh_merged)\n",
    "    valid_beh_vals_conf = behavioral_utils.get_rpe_groups_per_session(session, valid_beh_vals)\n",
    "\n",
    "    valid_beh_vals_conf[\"MaxFeatMatches\"] = valid_beh_vals_conf.MaxFeat == feat\n",
    "    valid_beh_vals_conf[\"Session\"] = session\n",
    "    return valid_beh_vals_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sessions = pd.read_pickle(SESSIONS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of sessions with at least N trials per condition for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at least 20 trials: \n",
      "CIRCLE: 12\n",
      "SQUARE: 17\n",
      "STAR: 11\n",
      "TRIANGLE: 10\n",
      "CYAN: 17\n",
      "GREEN: 12\n",
      "MAGENTA: 16\n",
      "YELLOW: 19\n",
      "ESCHER: 14\n",
      "POLKADOT: 13\n",
      "RIPPLE: 9\n",
      "SWIRL: 15\n"
     ]
    }
   ],
   "source": [
    "conditions = [\"MaxFeatMatches\", \"RPEGroup\"]\n",
    "min_num_trials = 20\n",
    "print(f\"at least {min_num_trials} trials: \")\n",
    "for feature in FEATURES:\n",
    "    res = pd.concat(valid_sessions.apply(lambda row: get_labels_for_session(row.session_name, feature), axis=1).values)\n",
    "    # res = res[res.Shape.isin([\"SQUARE\", \"TRIANGLE\"])]\n",
    "    res = res[res.Response == \"Correct\"]\n",
    "    sess_valid = res.groupby(\"Session\").apply(lambda group: behavioral_utils.validate_enough_trials_by_condition(group, conditions, min_num_trials))\n",
    "    valids = sess_valid[sess_valid]\n",
    "    print(f\"{feature}: {len(valids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of sessions that match OFC or HC sessions w at least N trials per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hip_sessions = [\n",
    "    '20180920', '20180918', '20180912', '20181008', '20181002',\n",
    "    '20181005', '201807250001', '20180926', '20181004', \n",
    "    '20181009','20181010', '20180921', '20180925', '20180910'\n",
    "]\n",
    "ofc_sessions = [\n",
    "    '20180709', '20180801', '201807250001', '20180802', '20180808',\n",
    "    '20180705', '20180921', '20180712', '20180910'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIRCLE: hip sessions 7, ofc sessions 3\n",
      "SQUARE: hip sessions 6, ofc sessions 6\n",
      "STAR: hip sessions 6, ofc sessions 3\n",
      "TRIANGLE: hip sessions 3, ofc sessions 4\n",
      "CYAN: hip sessions 9, ofc sessions 6\n",
      "GREEN: hip sessions 4, ofc sessions 4\n",
      "MAGENTA: hip sessions 8, ofc sessions 5\n",
      "YELLOW: hip sessions 10, ofc sessions 7\n",
      "ESCHER: hip sessions 9, ofc sessions 3\n",
      "POLKADOT: hip sessions 5, ofc sessions 4\n",
      "RIPPLE: hip sessions 6, ofc sessions 3\n",
      "SWIRL: hip sessions 8, ofc sessions 6\n"
     ]
    }
   ],
   "source": [
    "conditions = [\"MaxFeatMatches\", \"RPEGroup\"]\n",
    "min_num_trials = 20\n",
    "for feature in FEATURES:\n",
    "    res = pd.concat(valid_sessions.apply(lambda row: get_labels_for_session(row.session_name, feature), axis=1).values)\n",
    "    # res = res[res.Shape.isin([\"SQUARE\", \"TRIANGLE\"])]\n",
    "    res = res[res.Response == \"Correct\"]\n",
    "    sess_valid = res.groupby(\"Session\").apply(lambda group: behavioral_utils.validate_enough_trials_by_condition(group, conditions, min_num_trials))\n",
    "    valids = sess_valid[sess_valid]\n",
    "    hip_valids = valids[valids.index.isin(hip_sessions)]\n",
    "    ofc_valids = valids[valids.index.isin(ofc_sessions)]\n",
    "    print(f\"{feature}: hip sessions {len(hip_valids)}, ofc sessions {len(ofc_valids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session\n",
       "20180910    True\n",
       "20180912    True\n",
       "20180920    True\n",
       "20180921    True\n",
       "20180925    True\n",
       "20181002    True\n",
       "20181008    True\n",
       "20181010    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valids[valids.index.isin(hip_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
