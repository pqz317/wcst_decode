{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-examine feedback, action decoding, weights\n",
    "- re-run both with dropout layer\n",
    "- use same set of k-means clusters for electrodes\n",
    "- re-generate figures for weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from lfp_tools import (\n",
    "    general as lfp_general,\n",
    "    startup as lfp_startup,\n",
    "    development as lfp_development,\n",
    "    analysis as lfp_analysis\n",
    ")\n",
    "from spike_tools import (\n",
    "    general as spike_general,\n",
    "    analysis as spike_analysis,\n",
    ")\n",
    "import s3fs\n",
    "import utils.behavioral_utils as behavioral_utils\n",
    "import utils.spike_utils as spike_utils\n",
    "import utils.classifier_utils as classifier_utils\n",
    "import utils.visualization_utils as visualization_utils\n",
    "import utils.io_utils as io_utils\n",
    "from trial_splitters.random_splitter import RandomSplitter\n",
    "from trial_splitters.block_splitter import BlockSplitter\n",
    "from trial_splitters.kfold_splitter import KFoldSplitter\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from models.value_models import ValueNormedModel, ValueNormedDropoutModel\n",
    "import pickle\n",
    "\n",
    "from models.multinomial_logistic_regressor import MultinomialLogisticRegressor\n",
    "from models.model_wrapper import ModelWrapper, ModelWrapperLinearRegression\n",
    "\n",
    "from models.trainer import Trainer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import plotly.express as px\n",
    "import tensortools as tt\n",
    "\n",
    "import scipy.stats as sci_stats\n",
    "import scipy\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 150\n",
    "\n",
    "\n",
    "species = 'nhp'\n",
    "subject = 'SA'\n",
    "exp = 'WCST'\n",
    "session = 20180802  # this is the session for which there are spikes at the moment. \n",
    "\n",
    "feature_dims = [\"Color\", \"Shape\", \"Pattern\"]\n",
    "\n",
    "pre_interval = 1300\n",
    "post_interval = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab behavioral data, spike data, trial numbers. \n",
    "fs = s3fs.S3FileSystem()\n",
    "behavior_file = spike_general.get_behavior_path(subject, session)\n",
    "behavior_data = pd.read_csv(fs.open(behavior_file))\n",
    "valid_beh = behavior_data[behavior_data.Response.isin([\"Correct\", \"Incorrect\"])]   \n",
    "shuffled_card_idxs = behavioral_utils.get_shuffled_card_idxs(valid_beh)\n",
    "valid_beh = valid_beh[valid_beh.TrialNumber >= 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rates = pd.read_pickle(fs.open(\"l2l.pqz317.scratch/firing_rates_1300_fb_1500_100_bins.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating for bin 0.0\n",
      "Evaluating for bin 0.1\n",
      "Evaluating for bin 0.2\n",
      "Evaluating for bin 0.30000000000000004\n",
      "Evaluating for bin 0.4\n",
      "Evaluating for bin 0.5\n",
      "Evaluating for bin 0.6000000000000001\n",
      "Evaluating for bin 0.7000000000000001\n",
      "Evaluating for bin 0.8\n",
      "Evaluating for bin 0.9\n",
      "Evaluating for bin 1.0\n",
      "Evaluating for bin 1.1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.63 MiB already allocated; 11.00 MiB free; 4.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m labels \u001b[39m=\u001b[39m shuffled_card_idxs\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mItemChosen\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m     16\u001b[0m random_splitter \u001b[39m=\u001b[39m RandomSplitter(labels\u001b[39m.\u001b[39mTrialNumber\u001b[39m.\u001b[39munique(), \u001b[39m20\u001b[39m, \u001b[39m0.2\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[39m=\u001b[39m classifier_utils\u001b[39m.\u001b[39;49mevaluate_classifiers_by_time_bins(\n\u001b[1;32m     19\u001b[0m     wrapped, inputs, labels, np\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, \u001b[39m2.8\u001b[39;49m, \u001b[39m0.1\u001b[39;49m), random_splitter, cards\u001b[39m=\u001b[39;49mshuffled_card_idxs\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m io_utils\u001b[39m.\u001b[39msave_model_outputs(\n\u001b[1;32m     22\u001b[0m     fs, \n\u001b[1;32m     23\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvalued_normed_dropout\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     outputs\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m/src/wcst_decode/utils/classifier_utils.py:171\u001b[0m, in \u001b[0;36mevaluate_classifiers_by_time_bins\u001b[0;34m(clf, inputs, labels, time_bins, splitter, cards)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m# need isclose because the floats get stored weird\u001b[39;00m\n\u001b[1;32m    170\u001b[0m inputs_for_bin \u001b[39m=\u001b[39m inputs[np\u001b[39m.\u001b[39misclose(inputs[\u001b[39m\"\u001b[39m\u001b[39mTimeBins\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mbin\u001b[39m)]\n\u001b[0;32m--> 171\u001b[0m training_accs, test_accs, shuffled_accs, models \u001b[39m=\u001b[39m evaluate_classifier(\n\u001b[1;32m    172\u001b[0m     clf, inputs_for_bin, labels, splits, cards\u001b[39m=\u001b[39;49mcards\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m training_accs_by_bin[i, :] \u001b[39m=\u001b[39m training_accs\n\u001b[1;32m    175\u001b[0m test_accs_by_bin[i, :] \u001b[39m=\u001b[39m test_accs\n",
      "File \u001b[0;32m/src/wcst_decode/utils/classifier_utils.py:116\u001b[0m, in \u001b[0;36mevaluate_classifier\u001b[0;34m(clf, firing_rates, feature_selections, trial_splitter, cards, seed)\u001b[0m\n\u001b[1;32m    114\u001b[0m y_test \u001b[39m=\u001b[39m transform_to_label_data(feature_selections, trials_filter\u001b[39m=\u001b[39mtest_trials)\n\u001b[1;32m    115\u001b[0m \u001b[39m# print(\"|||||||NEW SPLIT ||||||||||\")\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit(x_train, y_train, cards_train)\n\u001b[1;32m    117\u001b[0m train_acc \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mscore(x_train, y_train, cards_train)\n\u001b[1;32m    118\u001b[0m \u001b[39m# print(f\"Train Score: {train_acc}\")\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[39m# to account for the fact that certain splitters with certain\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m# filters may result in no test data. \u001b[39;00m\n",
      "File \u001b[0;32m/src/wcst_decode/models/model_wrapper.py:25\u001b[0m, in \u001b[0;36mModelWrapper.fit\u001b[0;34m(self, x_train, y_train, cards_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m     cards_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(cards_train)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     24\u001b[0m dataset \u001b[39m=\u001b[39m (x_train, y_train, cards_train)\n\u001b[0;32m---> 25\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, dataset)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/src/wcst_decode/models/trainer.py:40\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, model, dataset, return_intermediates)\u001b[0m\n\u001b[1;32m     38\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m cards_train \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \n\u001b[0;32m---> 40\u001b[0m     out \u001b[39m=\u001b[39m model(x_train, cards_train)\n\u001b[1;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     out \u001b[39m=\u001b[39m model(x_train)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/src/wcst_decode/models/value_models.py:224\u001b[0m, in \u001b[0;36mValueNormedDropoutModel.forward\u001b[0;34m(self, neural_activity, card_masks)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m# batch_size x 12\u001b[39;00m\n\u001b[1;32m    223\u001b[0m feature_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequence(neural_activity)   \n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchoice_from_values(feature_values, card_masks)\n",
      "File \u001b[0;32m/src/wcst_decode/models/value_models.py:31\u001b[0m, in \u001b[0;36mFeatureValueBaseModel.choice_from_values\u001b[0;34m(self, feature_values, card_masks)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchoice_from_values\u001b[39m(\u001b[39mself\u001b[39m, feature_values, card_masks):\n\u001b[1;32m     28\u001b[0m     \u001b[39m# add dimension, repeat along added dim\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39m# new dims batch_size x 4 x 12\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     expanded \u001b[39m=\u001b[39m feature_values\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     masked \u001b[39m=\u001b[39m expanded \u001b[39m*\u001b[39;49m card_masks\n\u001b[1;32m     32\u001b[0m     values_agg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_func(masked, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_func \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mmax:\n\u001b[1;32m     34\u001b[0m         \u001b[39m# annoying check because max func returns both values and indices\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.63 MiB already allocated; 11.00 MiB free; 4.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_neurons = len(firing_rates.UnitID.unique())\n",
    "labels = np.sort(shuffled_card_idxs.ItemChosen.unique())\n",
    "init_params = {\"n_inputs\": num_neurons, \"p_dropout\": 0.5, \"n_values\": 12}\n",
    "# init_params = {\"n_inputs\": num_neurons, \"n_values\": 12}\n",
    "\n",
    "trainer = Trainer(learning_rate=0.05, max_iter=500, batch_size=10000)\n",
    "wrapped = ModelWrapper(ValueNormedDropoutModel, init_params, trainer, labels)\n",
    "# wrapped = ModelWrapper(ValueNormedModel, init_params, trainer, labels)\n",
    "\n",
    "mode = \"SpikeCounts\"\n",
    "\n",
    "# prep data for classification\n",
    "inputs = firing_rates.rename(columns={mode: \"Value\"})\n",
    "labels = shuffled_card_idxs.rename(columns={\"ItemChosen\": \"Feature\"})\n",
    "\n",
    "random_splitter = RandomSplitter(labels.TrialNumber.unique(), 20, 0.2)\n",
    "\n",
    "outputs = classifier_utils.evaluate_classifiers_by_time_bins(\n",
    "    wrapped, inputs, labels, np.arange(0, 2.8, 0.1), random_splitter, cards=shuffled_card_idxs\n",
    ")\n",
    "io_utils.save_model_outputs(\n",
    "    fs, \n",
    "    \"valued_normed_dropout\", \n",
    "    f\"{pre_interval}_fb_{post_interval}\",\n",
    "    \"random_split\",\n",
    "    outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
